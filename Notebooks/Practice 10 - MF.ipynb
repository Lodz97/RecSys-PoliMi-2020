{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems 2018/19\n",
    "\n",
    "### Practice session on BPR-MF\n",
    "\n",
    "\n",
    "## Recap on BPR\n",
    "S.Rendle et al. BPR: Bayesian Personalized Ranking from Implicit Feedback. UAI2009\n",
    "\n",
    "The usual approach for item recommenders is to predict a personalized score $\\hat{x}_{ui}$ for an item that reflects the preference of the user for the item. Then the items are ranked by sorting them according to that score.\n",
    "\n",
    "Machine learning approaches are tipically fit by using observed items as a positive sample and missing ones for the negative class. A perfect model would thus be useless, as it would classify as negative (non-interesting) all the items that were non-observed at training time. The only reason why such methods work is regularization.\n",
    "\n",
    "BPR use a different approach. The training dataset is composed by triplets $(u,i,j)$ representing that user u is assumed to prefer i over j. For an implicit dataset this means that u observed i but not j:\n",
    "$$D_S := \\{(u,i,j) \\mid i \\in I_u^+ \\wedge j \\in I \\setminus I_u^+\\}$$\n",
    "\n",
    "### BPR-OPT\n",
    "A machine learning model can be represented by a parameter vector $\\Theta$ which is found at fitting time. BPR wants to find the parameter vector that is most probable given the desired, but latent, preference structure $>_u$:\n",
    "$$p(\\Theta \\mid >_u) \\propto p(>_u \\mid \\Theta)p(\\Theta) $$\n",
    "$$\\prod_{u\\in U} p(>_u \\mid \\Theta) = \\dots = \\prod_{(u,i,j) \\in D_S} p(i >_u j \\mid \\Theta) $$\n",
    "\n",
    "The probability that a user really prefers item $i$ to item $j$ is defined as:\n",
    "$$ p(i >_u j \\mid \\Theta) := \\sigma(\\hat{x}_{uij}(\\Theta)) $$\n",
    "Where $\\sigma$ represent the logistic sigmoid and $\\hat{x}_{uij}(\\Theta)$ is an arbitrary real-valued function of $\\Theta$ (the output of your arbitrary model).\n",
    "\n",
    "\n",
    "To complete the Bayesian setting, we define a prior density for the parameters:\n",
    "$$p(\\Theta) \\sim N(0, \\Sigma_\\Theta)$$\n",
    "And we can now formulate the maximum posterior estimator:\n",
    "$$BPR-OPT := \\log p(\\Theta \\mid >_u) $$\n",
    "$$ = \\log p(>_u \\mid \\Theta) p(\\Theta) $$\n",
    "$$ = \\log \\prod_{(u,i,j) \\in D_S} \\sigma(\\hat{x}_{uij})p(\\Theta) $$\n",
    "$$ = \\sum_{(u,i,j) \\in D_S} \\log \\sigma(\\hat{x}_{uij}) + \\log p(\\Theta) $$\n",
    "$$ = \\sum_{(u,i,j) \\in D_S} \\log \\sigma(\\hat{x}_{uij}) - \\lambda_\\Theta ||\\Theta||^2 $$\n",
    "\n",
    "Where $\\lambda_\\Theta$ are model specific regularization parameters.\n",
    "\n",
    "### BPR learning algorithm\n",
    "Once obtained the log-likelihood, we need to maximize it in order to find our obtimal $\\Theta$. As the crierion is differentiable, gradient descent algorithms are an obvious choiche for maximization.\n",
    "\n",
    "Gradient descent comes in many fashions, you can find an overview on my master thesis https://www.politesi.polimi.it/bitstream/10589/133864/3/tesi.pdf on pages 18-19-20 (I'm linking my thesis just because I'm sure of what it's written there, many posts you can find online contain some error). A nice post about momentum is available here https://distill.pub/2017/momentum/\n",
    "\n",
    "The basic version of gradient descent consists in evaluating the gradient using all the available samples and then perform a single update. The problem with this is, in our case, that our training dataset is very skewed. Suppose an item i is very popular. Then we habe many terms of the form $\\hat{x}_{uij}$ in the loss because for many users u the item i is compared against all negative items j.\n",
    "\n",
    "The other popular approach is stochastic gradient descent, where for each training sample an update is performed. This is a better approach, but the order in which the samples are traversed is crucial. To solve this issue BPR uses a stochastic gradient descent algorithm that choses the triples randomly.\n",
    "\n",
    "The gradient of BPR-OPT with respect to the model parameters is: \n",
    "$$\\frac{\\partial BPR-OPT}{\\partial \\Theta} = \\sum_{(u,i,j) \\in D_S} \\frac{\\partial}{\\partial \\Theta} \\log \\sigma (\\hat{x}_{uij}) - \\lambda_\\Theta \\frac{\\partial}{\\partial\\Theta} || \\Theta ||^2$$\n",
    "$$ =  \\sum_{(u,i,j) \\in D_S} \\frac{-e^{-\\hat{x}_{uij}}}{1+e^{-\\hat{x}_{uij}}} \\frac{\\partial}{\\partial \\Theta}\\hat{x}_{uij} - \\lambda_\\Theta \\Theta $$\n",
    "\n",
    "### BPR-MF\n",
    "\n",
    "In order to practically apply this learning schema to an existing algorithm, we first split the real valued preference term: $\\hat{x}_{uij} := \\hat{x}_{ui} − \\hat{x}_{uj}$. And now we can apply any standard collaborative filtering model that predicts $\\hat{x}_{ui}$.\n",
    "\n",
    "The problem of predicting $\\hat{x}_{ui}$ can be seen as the task of estimating a matrix $X:U×I$. With matrix factorization teh target matrix $X$ is approximated by the matrix product of two low-rank matrices $W:|U|\\times k$ and $H:|I|\\times k$:\n",
    "$$X := WH^t$$\n",
    "The prediction formula can also be written as:\n",
    "$$\\hat{x}_{ui} = \\langle w_u,h_i \\rangle = \\sum_{f=1}^k w_{uf} \\cdot h_{if}$$\n",
    "Besides the dot product ⟨⋅,⋅⟩, in general any kernel can be used.\n",
    "\n",
    "We can now specify the derivatives:\n",
    "$$ \\frac{\\partial}{\\partial \\theta} \\hat{x}_{uij} = \\begin{cases}\n",
    "(h_{if} - h_{jf}) \\text{ if } \\theta=w_{uf}, \\\\\n",
    "w_{uf} \\text{ if } \\theta = h_{if}, \\\\\n",
    "-w_{uf} \\text{ if } \\theta = h_{jf}, \\\\\n",
    "0 \\text{ else }\n",
    "\\end{cases} $$\n",
    "\n",
    "Which basically means: user $u$ prefer $i$ over $j$, let's do the following:\n",
    "- Increase the relevance (according to $u$) of features belonging to $i$ but not to $j$ and vice-versa\n",
    "- Increase the relevance of features assigned to $i$\n",
    "- Decrease the relevance of features assigned to $j$\n",
    "\n",
    "We're now ready to look at some code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import zipfile, os\n",
    "\n",
    "# If file exists, skip the download\n",
    "data_file_path = \"data/Movielens_10M/\"\n",
    "data_file_name = data_file_path + \"movielens_10m.zip\"\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(data_file_path):\n",
    "    os.makedirs(data_file_path)\n",
    "\n",
    "if not os.path.exists(data_file_name):\n",
    "    urlretrieve (\"http://files.grouplens.org/datasets/movielens/ml-10m.zip\", data_file_name)\n",
    "    \n",
    "dataFile = zipfile.ZipFile(data_file_name)\n",
    "URM_path = dataFile.extract(\"ml-10M100K/ratings.dat\", path=\"data/Movielens_10M\")\n",
    "URM_file = open(URM_path, 'r')\n",
    "\n",
    "\n",
    "def rowSplit (rowString):\n",
    "    \n",
    "    split = rowString.split(\"::\")\n",
    "    split[3] = split[3].replace(\"\\n\",\"\")\n",
    "    \n",
    "    split[0] = int(split[0])\n",
    "    split[1] = int(split[1])\n",
    "    split[2] = float(split[2])\n",
    "    split[3] = int(split[3])\n",
    "    \n",
    "    result = tuple(split)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "URM_file.seek(0)\n",
    "URM_tuples = []\n",
    "\n",
    "for line in URM_file:\n",
    "   URM_tuples.append(rowSplit (line))\n",
    "\n",
    "userList, itemList, ratingList, timestampList = zip(*URM_tuples)\n",
    "\n",
    "userList = list(userList)\n",
    "itemList = list(itemList)\n",
    "ratingList = list(ratingList)\n",
    "timestampList = list(timestampList)\n",
    "\n",
    "import scipy.sparse as sps\n",
    "\n",
    "URM_all = sps.coo_matrix((ratingList, (userList, itemList)))\n",
    "URM_all = URM_all.tocsr()\n",
    "\n",
    "\n",
    "\n",
    "from Notebooks_utils.data_splitter import train_test_holdout\n",
    "\n",
    "\n",
    "URM_train, URM_test = train_test_holdout(URM_all, train_perc = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MF Computing prediction\n",
    "\n",
    "### In a MF model you have two matrices, one with a row per user and the other with a column per item. The other dimension, columns for the first one and rows for the second one is called latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factors = 10\n",
    "\n",
    "n_users, n_items = URM_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "user_factors = np.random.random((n_users, num_factors))\n",
    "\n",
    "item_factors = np.random.random((n_items, num_factors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To compute the prediction we have to muliply the user factors to the item factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is 1.74\n"
     ]
    }
   ],
   "source": [
    "item_index = 15\n",
    "user_index = 42\n",
    "\n",
    "prediction = np.dot(user_factors[user_index,:], item_factors[item_index,:])\n",
    "\n",
    "print(\"Prediction is {:.2f}\".format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a MF MSE model\n",
    "\n",
    "### Use SGD as we saw for SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error is 3.26\n"
     ]
    }
   ],
   "source": [
    "test_data = 5\n",
    "learning_rate = 1e-2\n",
    "regularization = 1e-3\n",
    "\n",
    "gradient = test_data - prediction\n",
    "\n",
    "print(\"Prediction error is {:.2f}\".format(gradient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy original value to avoid messing up the updates\n",
    "H_i = item_factors[item_index,:]\n",
    "W_u = user_factors[user_index,:]\n",
    "\n",
    "user_factors[user_index,:] += learning_rate * (gradient * H_i - regularization * W_u)\n",
    "item_factors[item_index,:] += learning_rate * (gradient * W_u - regularization * H_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction after the update is 1.93\n",
      "Prediction error is 3.07\n"
     ]
    }
   ],
   "source": [
    "prediction = np.dot(user_factors[user_index,:], item_factors[item_index,:])\n",
    "\n",
    "print(\"Prediction after the update is {:.2f}\".format(prediction))\n",
    "print(\"Prediction error is {:.2f}\".format(test_data - prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARNING: Initialization must be done with random non-zero values ... otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_factors = np.zeros((n_users, num_factors))\n",
    "\n",
    "item_factors = np.zeros((n_items, num_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is 0.00\n",
      "Prediction error is 5.00\n"
     ]
    }
   ],
   "source": [
    "prediction = np.dot(user_factors[user_index,:], item_factors[item_index,:])\n",
    "\n",
    "print(\"Prediction is {:.2f}\".format(prediction))\n",
    "\n",
    "gradient = test_data - prediction\n",
    "\n",
    "print(\"Prediction error is {:.2f}\".format(gradient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_i = item_factors[item_index,:]\n",
    "W_u = user_factors[user_index,:]\n",
    "\n",
    "user_factors[user_index,:] += learning_rate * (gradient * H_i - regularization * W_u)\n",
    "item_factors[item_index,:] += learning_rate * (gradient * W_u - regularization * H_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction after the update is 0.00\n",
      "Prediction error is 5.00\n"
     ]
    }
   ],
   "source": [
    "prediction = np.dot(user_factors[user_index,:], item_factors[item_index,:])\n",
    "\n",
    "print(\"Prediction after the update is {:.2f}\".format(prediction))\n",
    "print(\"Prediction error is {:.2f}\".format(test_data - prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the updates multiply the gradient and the latent factors, if those are zero the SGD will never be able to move from that point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a MF BPR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basics are the same, except for how we compute the gradient, we have to sample a triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM_mask = URM_train.copy()\n",
    "URM_mask.data[URM_mask.data <= 3] = 0\n",
    "\n",
    "URM_mask.eliminate_zeros()\n",
    "\n",
    "# Extract users having at least one interaction to choose from\n",
    "eligibleUsers = []\n",
    "\n",
    "for user_id in range(n_users):\n",
    "\n",
    "    start_pos = URM_mask.indptr[user_id]\n",
    "    end_pos = URM_mask.indptr[user_id+1]\n",
    "\n",
    "    if len(URM_mask.indices[start_pos:end_pos]) > 0:\n",
    "        eligibleUsers.append(user_id)\n",
    "                \n",
    "                \n",
    "\n",
    "def sampleTriplet():\n",
    "    \n",
    "    # By randomly selecting a user in this way we could end up \n",
    "    # with a user with no interactions\n",
    "    #user_id = np.random.randint(0, n_users)\n",
    "    \n",
    "    user_id = np.random.choice(eligibleUsers)\n",
    "    \n",
    "    # Get user seen items and choose one\n",
    "    userSeenItems = URM_mask[user_id,:].indices\n",
    "    pos_item_id = np.random.choice(userSeenItems)\n",
    "\n",
    "    negItemSelected = False\n",
    "\n",
    "    # It's faster to just try again then to build a mapping of the non-seen items\n",
    "    while (not negItemSelected):\n",
    "        neg_item_id = np.random.randint(0, n_items)\n",
    "\n",
    "        if (neg_item_id not in userSeenItems):\n",
    "            \n",
    "            negItemSelected = True\n",
    "\n",
    "    return user_id, pos_item_id, neg_item_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70735, 1748, 21851)\n",
      "(29107, 5995, 13801)\n",
      "(947, 2406, 10918)\n",
      "(19871, 457, 54234)\n",
      "(45728, 1318, 52817)\n",
      "(36838, 342, 33240)\n",
      "(5071, 165, 5468)\n",
      "(5779, 2280, 64413)\n",
      "(17119, 11, 43205)\n",
      "(48172, 2571, 10322)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(sampleTriplet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_factors = np.random.random((n_users, num_factors))\n",
    "item_factors = np.random.random((n_items, num_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21831 508 51822\n"
     ]
    }
   ],
   "source": [
    "user_id, positive_item, negative_item = sampleTriplet()\n",
    "\n",
    "print(user_id, positive_item, negative_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7264682977647943"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_uij = np.dot(user_factors[user_id, :], (item_factors[positive_item,:] - item_factors[negative_item,:]))\n",
    "\n",
    "x_uij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15103988084996914"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_item = 1 / (1 + np.exp(x_uij))\n",
    "\n",
    "sigmoid_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When using BPR we have to update three components, the user factors and the item factors of both the positive and negative item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H_i = item_factors[positive_item,:]\n",
    "H_j = item_factors[negative_item,:]\n",
    "W_u = user_factors[user_id,:]\n",
    "\n",
    "\n",
    "user_factors[user_index,:] += learning_rate * (sigmoid_item * ( H_i - H_j ) - regularization * W_u)\n",
    "item_factors[positive_item,:] += learning_rate * (sigmoid_item * ( W_u ) - regularization * H_i)\n",
    "item_factors[negative_item,:] += learning_rate * (sigmoid_item * (-W_u ) - regularization * H_j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.738394989175958"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_uij = np.dot(user_factors[user_id, :], (item_factors[positive_item,:] - item_factors[negative_item,:]))\n",
    "\n",
    "x_uij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.64238   , 1.33704803, 1.91010916, ..., 2.51305353, 2.08655125,\n",
       "       2.68833044])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How to rank items with MF ?\n",
    "\n",
    "## Compute the prediction for all items and rank them\n",
    "\n",
    "item_scores = np.dot(user_factors[user_index,:], item_factors.T)\n",
    "item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65134,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping, how to used and when it is needed\n",
    "\n",
    "### Problem, how many epochs? 5, 10, 150, 2487 ?\n",
    "\n",
    "### We could try different values in increasing order: 5, 10, 15, 20, 25...\n",
    "### However, in this way we would train up to a point, test and then discard the model, to re-train it again up to that same point and then some more... not a good idea.\n",
    "\n",
    "### Early stopping! \n",
    "* Train the model up to a certain number of epochs, say 5\n",
    "* Compute the recommendation quality on the validation set\n",
    "* Train for other 5 epochs\n",
    "* Compute the recommendation quality on the validation set AND compare it with the previous one. If better, then we have another best model, if not, go ahead...\n",
    "* Repeat until you have either reached the max number of epoch you want to allow (e.g., 300) or a certain number of contiguous validation seps have not updated te best model\n",
    "\n",
    "### Advantages:\n",
    "* Easy to implement, we already have all that is required, a train function, a predictor function and an evaluator\n",
    "* MUCH faster than retraining everything from the beginning\n",
    "* Often allows to reach even better solutions\n",
    "\n",
    "### Challenges:\n",
    "* The evaluation step may be very slow compared to the time it takes to re-train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a PureSVD model\n",
    "\n",
    "### As opposed to the previous ones, PureSVD relies on the SVD decomposition of the URM, which is an easily available function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "# Other SVDs are also available, like from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Sigma, VT = randomized_svd(URM_train,\n",
    "              n_components=num_factors,\n",
    "              #n_iter=5,\n",
    "              random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06361265e-22,  8.40935702e-17,  8.50010407e-16, ...,\n",
       "         2.45254722e-15,  9.48277371e-16, -3.54568146e-15],\n",
       "       [ 8.59745974e-04, -3.36843680e-03, -7.90044382e-04, ...,\n",
       "        -8.81207236e-04, -2.16693248e-03, -1.19207403e-04],\n",
       "       [ 5.70997490e-04, -1.39024014e-03, -2.56976795e-04, ...,\n",
       "         2.64430812e-03,  1.96766510e-03,  8.26974282e-04],\n",
       "       ...,\n",
       "       [ 3.13594599e-03,  1.55684804e-03,  5.38902703e-03, ...,\n",
       "        -1.42657566e-03,  3.00583309e-03,  2.23597019e-03],\n",
       "       [ 1.22178385e-03, -5.26678849e-03,  1.19623250e-03, ...,\n",
       "        -7.49036248e-05, -1.69857146e-03,  2.56664448e-03],\n",
       "       [ 1.23230217e-03, -2.68338232e-04, -6.32760148e-04, ...,\n",
       "         2.45695255e-03, -1.34372812e-03,  4.13393456e-03]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71568, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4274.95500448, 1783.67004383, 1533.9859579 , 1227.92689579,\n",
       "       1184.72071643, 1013.99745833,  960.27315676,  908.38172069,\n",
       "        843.04010687,  745.66796854])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.91792537e-22,  8.02497822e-02,  3.44842715e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  4.35614245e-05],\n",
       "       [-5.20176601e-16, -4.52061362e-02, -5.03095688e-02, ...,\n",
       "        -0.00000000e+00, -0.00000000e+00,  7.09105665e-05],\n",
       "       [-9.55039973e-16, -1.14378476e-02, -2.11044482e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.71196832e-06],\n",
       "       ...,\n",
       "       [ 2.78140196e-16,  1.44694433e-01,  2.48286022e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.38541899e-04],\n",
       "       [ 1.57614670e-16, -3.80283247e-02, -2.96388908e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.10929324e-05],\n",
       "       [ 1.27757327e-16, -9.59188228e-03, -1.39591606e-03, ...,\n",
       "        -0.00000000e+00, -0.00000000e+00,  4.09184806e-05]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 65134)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncating the number of singular values introduces an approximation which allows to fill the missing urm entries\n",
    "\n",
    "### Computing a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store an intermediate pre-multiplied matrix\n",
    "\n",
    "s_Vt = sps.diags(Sigma)*VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is 0.03\n"
     ]
    }
   ],
   "source": [
    "prediction = U[user_index, :].dot(s_Vt[:,item_index])\n",
    "\n",
    "print(\"Prediction is {:.2f}\".format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.68597132e-16,  7.24899190e-01,  4.42185258e-01, ...,\n",
       "        0.00000000e+00,  0.00000000e+00,  2.67442759e-04])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_scores = U[user_index, :].dot(s_Vt)\n",
    "item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65134,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's compare the three MF: BPR, FunkSVD and PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixFactorization.Cython.MatrixFactorization_Cython import MatrixFactorization_BPR_Cython, MatrixFactorization_FunkSVD_Cython\n",
    "from MatrixFactorization.PureSVDRecommender import PureSVDRecommender\n",
    "\n",
    "from Base.Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[5])\n",
    "\n",
    "evaluator_validation_early_stopping = EvaluatorHoldout(URM_train, cutoff_list=[5], exclude_seen = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixFactorization_BPR_Cython_Recommender: URM Detected 1690 (2.36 %) cold users.\n",
      "MatrixFactorization_BPR_Cython_Recommender: URM Detected 54481 (83.64 %) cold items.\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.53 seconds. BPR loss 1.00E-02. Sample per second: 134836\n",
      "MF_BPR: Epoch 1 of 300. Elapsed time 0.40 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.83 seconds. BPR loss 1.00E-02. Sample per second: 85770\n",
      "MF_BPR: Epoch 2 of 300. Elapsed time 0.71 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.13 seconds. BPR loss 1.01E-02. Sample per second: 62830\n",
      "MF_BPR: Epoch 3 of 300. Elapsed time 1.00 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.40 seconds. BPR loss 9.99E-03. Sample per second: 176945\n",
      "MF_BPR: Epoch 4 of 300. Elapsed time 1.27 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.67 seconds. BPR loss 1.00E-02. Sample per second: 105906\n",
      "MF_BPR: Epoch 5 of 300. Elapsed time 1.54 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.92 seconds. BPR loss 1.01E-02. Sample per second: 76887\n",
      "MF_BPR: Epoch 6 of 300. Elapsed time 1.80 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.18 seconds. BPR loss 1.02E-02. Sample per second: 59946\n",
      "MF_BPR: Epoch 7 of 300. Elapsed time 2.06 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.44 seconds. BPR loss 1.01E-02. Sample per second: 162259\n",
      "MF_BPR: Epoch 8 of 300. Elapsed time 2.31 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.69 seconds. BPR loss 1.01E-02. Sample per second: 102872\n",
      "MF_BPR: Epoch 9 of 300. Elapsed time 2.56 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.94 seconds. BPR loss 1.01E-02. Sample per second: 75827\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 16694 ( 23.89% ) in 30.01 sec. Users per second: 556\n",
      "EvaluatorHoldout: Processed 34001 ( 48.66% ) in 1.01 min. Users per second: 561\n",
      "EvaluatorHoldout: Processed 52001 ( 74.42% ) in 1.53 min. Users per second: 567\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.02 min. Users per second: 577\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0043803, PRECISION: 0.0017316, PRECISION_RECALL_MIN_DEN: 0.0017316, RECALL: 0.0000697, MAP: 0.0008089, MRR: 0.0040246, NDCG: 0.0001492, F1: 0.0001340, HIT_RATE: 0.0086579, ARHR: 0.0040347, RMSE: 3.7473014, NOVELTY: 0.0002032, AVERAGE_POPULARITY: 0.0041145, DIVERSITY_MEAN_INTER_LIST: 0.9996262, DIVERSITY_HERFINDAHL: 0.9999224, COVERAGE_ITEM: 0.6478951, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.4046616, SHANNON_ENTROPY: 14.4132402, \n",
      "\n",
      "MF_BPR: New best model found! Updating.\n",
      "MF_BPR: Epoch 10 of 300. Elapsed time 2.07 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.44 seconds. BPR loss 1.01E-02. Sample per second: 162210\n",
      "MF_BPR: Epoch 11 of 300. Elapsed time 2.07 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.70 seconds. BPR loss 1.01E-02. Sample per second: 100958\n",
      "MF_BPR: Epoch 12 of 300. Elapsed time 2.08 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.95 seconds. BPR loss 1.00E-02. Sample per second: 75070\n",
      "MF_BPR: Epoch 13 of 300. Elapsed time 2.08 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.20 seconds. BPR loss 1.01E-02. Sample per second: 59379\n",
      "MF_BPR: Epoch 14 of 300. Elapsed time 2.08 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.43 seconds. BPR loss 1.01E-02. Sample per second: 165099\n",
      "MF_BPR: Epoch 15 of 300. Elapsed time 2.09 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.66 seconds. BPR loss 1.01E-02. Sample per second: 106869\n",
      "MF_BPR: Epoch 16 of 300. Elapsed time 2.09 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.92 seconds. BPR loss 1.00E-02. Sample per second: 76958\n",
      "MF_BPR: Epoch 17 of 300. Elapsed time 2.10 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.16 seconds. BPR loss 1.01E-02. Sample per second: 61211\n",
      "MF_BPR: Epoch 18 of 300. Elapsed time 2.10 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.39 seconds. BPR loss 1.00E-02. Sample per second: 180089\n",
      "MF_BPR: Epoch 19 of 300. Elapsed time 2.10 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.64 seconds. BPR loss 1.01E-02. Sample per second: 110217\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 16225 ( 23.22% ) in 30.00 sec. Users per second: 541\n",
      "EvaluatorHoldout: Processed 31001 ( 44.36% ) in 1.01 min. Users per second: 510\n",
      "EvaluatorHoldout: Processed 47310 ( 67.70% ) in 1.51 min. Users per second: 521\n",
      "EvaluatorHoldout: Processed 64001 ( 91.59% ) in 2.02 min. Users per second: 529\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.16 min. Users per second: 539\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0043803, PRECISION: 0.0017316, PRECISION_RECALL_MIN_DEN: 0.0017316, RECALL: 0.0000697, MAP: 0.0008089, MRR: 0.0040246, NDCG: 0.0001492, F1: 0.0001340, HIT_RATE: 0.0086579, ARHR: 0.0040347, RMSE: 3.7473013, NOVELTY: 0.0002032, AVERAGE_POPULARITY: 0.0041144, DIVERSITY_MEAN_INTER_LIST: 0.9996262, DIVERSITY_HERFINDAHL: 0.9999224, COVERAGE_ITEM: 0.6478951, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.4046632, SHANNON_ENTROPY: 14.4132442, \n",
      "\n",
      "MF_BPR: Epoch 20 of 300. Elapsed time 4.27 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.65 seconds. BPR loss 1.01E-02. Sample per second: 108712\n",
      "MF_BPR: Epoch 21 of 300. Elapsed time 4.28 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.89 seconds. BPR loss 1.01E-02. Sample per second: 79956\n",
      "MF_BPR: Epoch 22 of 300. Elapsed time 4.28 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.12 seconds. BPR loss 1.01E-02. Sample per second: 63158\n",
      "MF_BPR: Epoch 23 of 300. Elapsed time 4.28 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.37 seconds. BPR loss 1.01E-02. Sample per second: 190721\n",
      "MF_BPR: Epoch 24 of 300. Elapsed time 4.29 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.62 seconds. BPR loss 1.01E-02. Sample per second: 113978\n",
      "MF_BPR: Epoch 25 of 300. Elapsed time 4.29 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.87 seconds. BPR loss 1.01E-02. Sample per second: 81554\n",
      "MF_BPR: Epoch 26 of 300. Elapsed time 4.30 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.12 seconds. BPR loss 1.01E-02. Sample per second: 63551\n",
      "MF_BPR: Epoch 27 of 300. Elapsed time 4.30 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.37 seconds. BPR loss 1.00E-02. Sample per second: 192346\n",
      "MF_BPR: Epoch 28 of 300. Elapsed time 4.30 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.62 seconds. BPR loss 1.01E-02. Sample per second: 114035\n",
      "MF_BPR: Epoch 29 of 300. Elapsed time 4.31 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.87 seconds. BPR loss 1.02E-02. Sample per second: 81697\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 17001 ( 24.33% ) in 31.12 sec. Users per second: 546\n",
      "EvaluatorHoldout: Processed 35001 ( 50.09% ) in 1.03 min. Users per second: 564\n",
      "EvaluatorHoldout: Processed 53001 ( 75.85% ) in 1.55 min. Users per second: 571\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.01 min. Users per second: 580\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0043767, PRECISION: 0.0017316, PRECISION_RECALL_MIN_DEN: 0.0017316, RECALL: 0.0000697, MAP: 0.0008087, MRR: 0.0040234, NDCG: 0.0001492, F1: 0.0001340, HIT_RATE: 0.0086579, ARHR: 0.0040335, RMSE: 3.7473012, NOVELTY: 0.0002032, AVERAGE_POPULARITY: 0.0041145, DIVERSITY_MEAN_INTER_LIST: 0.9996262, DIVERSITY_HERFINDAHL: 0.9999224, COVERAGE_ITEM: 0.6478951, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.4046616, SHANNON_ENTROPY: 14.4132402, \n",
      "\n",
      "MF_BPR: Epoch 30 of 300. Elapsed time 6.32 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.72 seconds. BPR loss 1.01E-02. Sample per second: 99265\n",
      "MF_BPR: Epoch 31 of 300. Elapsed time 6.33 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.96 seconds. BPR loss 1.01E-02. Sample per second: 74336\n",
      "MF_BPR: Epoch 32 of 300. Elapsed time 6.33 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.20 seconds. BPR loss 1.01E-02. Sample per second: 58968\n",
      "MF_BPR: Epoch 33 of 300. Elapsed time 6.33 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.45 seconds. BPR loss 9.96E-03. Sample per second: 157662\n",
      "MF_BPR: Epoch 34 of 300. Elapsed time 6.34 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.70 seconds. BPR loss 1.00E-02. Sample per second: 101226\n",
      "MF_BPR: Epoch 35 of 300. Elapsed time 6.34 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.96 seconds. BPR loss 1.00E-02. Sample per second: 73863\n",
      "MF_BPR: Epoch 36 of 300. Elapsed time 6.35 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.21 seconds. BPR loss 1.01E-02. Sample per second: 58482\n",
      "MF_BPR: Epoch 37 of 300. Elapsed time 6.35 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.46 seconds. BPR loss 1.01E-02. Sample per second: 155486\n",
      "MF_BPR: Epoch 38 of 300. Elapsed time 6.36 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.71 seconds. BPR loss 1.01E-02. Sample per second: 100433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF_BPR: Epoch 39 of 300. Elapsed time 6.36 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.95 seconds. BPR loss 1.00E-02. Sample per second: 74528\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 17001 ( 24.33% ) in 31.07 sec. Users per second: 547\n",
      "EvaluatorHoldout: Processed 33001 ( 47.23% ) in 1.02 min. Users per second: 540\n",
      "EvaluatorHoldout: Processed 50001 ( 71.55% ) in 1.52 min. Users per second: 549\n",
      "EvaluatorHoldout: Processed 68001 ( 97.31% ) in 2.04 min. Users per second: 556\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.07 min. Users per second: 563\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0043767, PRECISION: 0.0017316, PRECISION_RECALL_MIN_DEN: 0.0017316, RECALL: 0.0000697, MAP: 0.0008087, MRR: 0.0040234, NDCG: 0.0001492, F1: 0.0001340, HIT_RATE: 0.0086579, ARHR: 0.0040335, RMSE: 3.7473011, NOVELTY: 0.0002032, AVERAGE_POPULARITY: 0.0041145, DIVERSITY_MEAN_INTER_LIST: 0.9996262, DIVERSITY_HERFINDAHL: 0.9999224, COVERAGE_ITEM: 0.6478951, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.4046616, SHANNON_ENTROPY: 14.4132402, \n",
      "\n",
      "MF_BPR: Epoch 40 of 300. Elapsed time 8.44 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.55 seconds. BPR loss 1.01E-02. Sample per second: 129136\n",
      "MF_BPR: Epoch 41 of 300. Elapsed time 8.44 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.79 seconds. BPR loss 1.01E-02. Sample per second: 89864\n",
      "MF_BPR: Epoch 42 of 300. Elapsed time 8.44 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.04 seconds. BPR loss 1.01E-02. Sample per second: 68370\n",
      "MF_BPR: Epoch 43 of 300. Elapsed time 8.45 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.29 seconds. BPR loss 1.01E-02. Sample per second: 247241\n",
      "MF_BPR: Epoch 44 of 300. Elapsed time 8.45 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.52 seconds. BPR loss 1.01E-02. Sample per second: 137198\n",
      "MF_BPR: Epoch 45 of 300. Elapsed time 8.46 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.77 seconds. BPR loss 1.00E-02. Sample per second: 92453\n",
      "MF_BPR: Epoch 46 of 300. Elapsed time 8.46 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.02 seconds. BPR loss 1.01E-02. Sample per second: 69507\n",
      "MF_BPR: Epoch 47 of 300. Elapsed time 8.46 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.27 seconds. BPR loss 1.00E-02. Sample per second: 261168\n",
      "MF_BPR: Epoch 48 of 300. Elapsed time 8.47 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.53 seconds. BPR loss 1.01E-02. Sample per second: 135204\n",
      "MF_BPR: Epoch 49 of 300. Elapsed time 8.47 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.78 seconds. BPR loss 1.02E-02. Sample per second: 91504\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 17001 ( 24.33% ) in 31.19 sec. Users per second: 545\n",
      "EvaluatorHoldout: Processed 35001 ( 50.09% ) in 1.03 min. Users per second: 564\n",
      "EvaluatorHoldout: Processed 53001 ( 75.85% ) in 1.55 min. Users per second: 569\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.01 min. Users per second: 581\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0043767, PRECISION: 0.0017316, PRECISION_RECALL_MIN_DEN: 0.0017316, RECALL: 0.0000697, MAP: 0.0008087, MRR: 0.0040234, NDCG: 0.0001492, F1: 0.0001340, HIT_RATE: 0.0086579, ARHR: 0.0040335, RMSE: 3.7473009, NOVELTY: 0.0002032, AVERAGE_POPULARITY: 0.0041145, DIVERSITY_MEAN_INTER_LIST: 0.9996262, DIVERSITY_HERFINDAHL: 0.9999224, COVERAGE_ITEM: 0.6478951, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.4046628, SHANNON_ENTROPY: 14.4132445, \n",
      "\n",
      "MF_BPR: Epoch 50 of 300. Elapsed time 10.48 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.42 seconds. BPR loss 1.00E-02. Sample per second: 167322\n",
      "MF_BPR: Epoch 51 of 300. Elapsed time 10.49 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.66 seconds. BPR loss 1.00E-02. Sample per second: 107960\n",
      "MF_BPR: Epoch 52 of 300. Elapsed time 10.49 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.91 seconds. BPR loss 1.02E-02. Sample per second: 78195\n",
      "MF_BPR: Epoch 53 of 300. Elapsed time 10.50 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.16 seconds. BPR loss 1.01E-02. Sample per second: 61460\n",
      "MF_BPR: Epoch 54 of 300. Elapsed time 10.50 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.39 seconds. BPR loss 1.01E-02. Sample per second: 181486\n",
      "MF_BPR: Epoch 55 of 300. Elapsed time 10.50 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.64 seconds. BPR loss 1.01E-02. Sample per second: 111092\n",
      "MF_BPR: Epoch 56 of 300. Elapsed time 10.51 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.88 seconds. BPR loss 1.00E-02. Sample per second: 81126\n",
      "MF_BPR: Epoch 57 of 300. Elapsed time 10.51 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.12 seconds. BPR loss 1.01E-02. Sample per second: 63154\n",
      "MF_BPR: Epoch 58 of 300. Elapsed time 10.52 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.38 seconds. BPR loss 1.01E-02. Sample per second: 188329\n",
      "MF_BPR: Epoch 59 of 300. Elapsed time 10.52 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.61 seconds. BPR loss 1.01E-02. Sample per second: 115652\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 17001 ( 24.33% ) in 30.57 sec. Users per second: 556\n",
      "EvaluatorHoldout: Processed 35001 ( 50.09% ) in 1.01 min. Users per second: 575\n",
      "EvaluatorHoldout: Processed 53001 ( 75.85% ) in 1.52 min. Users per second: 580\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 1.99 min. Users per second: 585\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0043767, PRECISION: 0.0017316, PRECISION_RECALL_MIN_DEN: 0.0017316, RECALL: 0.0000697, MAP: 0.0008087, MRR: 0.0040234, NDCG: 0.0001492, F1: 0.0001340, HIT_RATE: 0.0086579, ARHR: 0.0040335, RMSE: 3.7473008, NOVELTY: 0.0002032, AVERAGE_POPULARITY: 0.0041140, DIVERSITY_MEAN_INTER_LIST: 0.9996262, DIVERSITY_HERFINDAHL: 0.9999224, COVERAGE_ITEM: 0.6478951, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.4046678, SHANNON_ENTROPY: 14.4132594, \n",
      "\n",
      "MF_BPR: Convergence reached! Terminating at epoch 60. Best value for 'MAP' at epoch 10 is 0.0008. Elapsed time 12.52 min\n",
      "MF_BPR: Epoch 60 of 300. Elapsed time 12.52 min\n",
      "EvaluatorHoldout: Processed 17001 ( 24.35% ) in 30.12 sec. Users per second: 564\n",
      "EvaluatorHoldout: Processed 35001 ( 50.14% ) in 1.00 min. Users per second: 581\n",
      "EvaluatorHoldout: Processed 53001 ( 75.93% ) in 1.51 min. Users per second: 586\n",
      "EvaluatorHoldout: Processed 69805 ( 100.00% ) in 1.96 min. Users per second: 594\n"
     ]
    }
   ],
   "source": [
    "recommender = MatrixFactorization_BPR_Cython(URM_train)\n",
    "recommender.fit(num_factors = 50, \n",
    "                validation_every_n = 10, \n",
    "                stop_on_validation = True, \n",
    "                evaluator_object = evaluator_validation_early_stopping,\n",
    "                lower_validations_allowed = 5, \n",
    "                validation_metric = \"MAP\")\n",
    "\n",
    "result_dict, _ = evaluator_test.evaluateRecommender(recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: {'ROC_AUC': 0.0010923286297543156,\n",
       "  'PRECISION': 0.0004412291383138733,\n",
       "  'PRECISION_RECALL_MIN_DEN': 0.0004457655850822519,\n",
       "  'RECALL': 8.133819467011618e-05,\n",
       "  'MAP': 0.00019785274852963388,\n",
       "  'MRR': 0.0009834539073132309,\n",
       "  'NDCG': 0.00010500043733765248,\n",
       "  'F1': 0.00013735562589175856,\n",
       "  'HIT_RATE': 0.0022061456915693717,\n",
       "  'ARHR': 0.0009834539073132309,\n",
       "  'RMSE': 3.7381009608792857,\n",
       "  'NOVELTY': 0.00020195889984728468,\n",
       "  'AVERAGE_POPULARITY': 0.003769269591917909,\n",
       "  'DIVERSITY_MEAN_INTER_LIST': 0.9996264277562489,\n",
       "  'DIVERSITY_HERFINDAHL': 0.9999224214973059,\n",
       "  'COVERAGE_ITEM': 0.6478490496514877,\n",
       "  'COVERAGE_USER': 0.9753660854012967,\n",
       "  'DIVERSITY_GINI': 0.4047776492495892,\n",
       "  'SHANNON_ENTROPY': 14.413630172798793}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixFactorization_FunkSVD_Cython_Recommender: URM Detected 1690 (2.36 %) cold users.\n",
      "MatrixFactorization_FunkSVD_Cython_Recommender: URM Detected 54481 (83.64 %) cold items.\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 18.63 seconds. MSE loss 1.96E+00. Sample per second: 429422\n",
      "FUNK_SVD: Epoch 1 of 300. Elapsed time 18.30 sec\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.39 seconds. MSE loss 1.14E+00. Sample per second: 460158\n",
      "FUNK_SVD: Epoch 2 of 300. Elapsed time 35.05 sec\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.12 seconds. MSE loss 1.13E+00. Sample per second: 467176\n",
      "FUNK_SVD: Epoch 3 of 300. Elapsed time 51.79 sec\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.98 seconds. MSE loss 1.13E+00. Sample per second: 471184\n",
      "FUNK_SVD: Epoch 4 of 300. Elapsed time 1.14 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.68 seconds. MSE loss 1.13E+00. Sample per second: 452580\n",
      "FUNK_SVD: Epoch 5 of 300. Elapsed time 1.42 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.37 seconds. MSE loss 1.12E+00. Sample per second: 460550\n",
      "FUNK_SVD: Epoch 6 of 300. Elapsed time 1.70 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.08 seconds. MSE loss 1.12E+00. Sample per second: 468321\n",
      "FUNK_SVD: Epoch 7 of 300. Elapsed time 1.98 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.79 seconds. MSE loss 1.12E+00. Sample per second: 476405\n",
      "FUNK_SVD: Epoch 8 of 300. Elapsed time 2.26 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.52 seconds. MSE loss 1.12E+00. Sample per second: 456560\n",
      "FUNK_SVD: Epoch 9 of 300. Elapsed time 2.54 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.19 seconds. MSE loss 1.11E+00. Sample per second: 465392\n",
      "FUNK_SVD: Validation begins...\n",
      "EvaluatorHoldout: Processed 14001 ( 20.04% ) in 30.38 sec. Users per second: 461\n",
      "EvaluatorHoldout: Processed 28488 ( 40.77% ) in 1.01 min. Users per second: 472\n",
      "EvaluatorHoldout: Processed 43001 ( 61.54% ) in 1.53 min. Users per second: 468\n",
      "EvaluatorHoldout: Processed 58001 ( 83.00% ) in 2.03 min. Users per second: 476\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.40 min. Users per second: 485\n",
      "FUNK_SVD: CUTOFF: 5 - ROC_AUC: 0.3846239, PRECISION: 0.1812158, PRECISION_RECALL_MIN_DEN: 0.1812158, RECALL: 0.0141211, MAP: 0.1349305, MRR: 0.4023555, NDCG: 0.0451037, F1: 0.0262006, HIT_RATE: 0.9060792, ARHR: 0.5224990, RMSE: 1.0228562, NOVELTY: 0.0004408, AVERAGE_POPULARITY: 0.4525306, DIVERSITY_MEAN_INTER_LIST: 0.7760762, DIVERSITY_HERFINDAHL: 0.9552130, COVERAGE_ITEM: 0.4913102, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.2049683, SHANNON_ENTROPY: 9.3882796, \n",
      "\n",
      "FUNK_SVD: New best model found! Updating.\n",
      "FUNK_SVD: Epoch 10 of 300. Elapsed time 5.22 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.94 seconds. MSE loss 1.11E+00. Sample per second: 472393\n",
      "FUNK_SVD: Epoch 11 of 300. Elapsed time 5.49 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.54 seconds. MSE loss 1.11E+00. Sample per second: 456018\n",
      "FUNK_SVD: Epoch 12 of 300. Elapsed time 5.77 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.07 seconds. MSE loss 1.11E+00. Sample per second: 468576\n",
      "FUNK_SVD: Epoch 13 of 300. Elapsed time 6.05 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.65 seconds. MSE loss 1.10E+00. Sample per second: 480464\n",
      "FUNK_SVD: Epoch 14 of 300. Elapsed time 6.32 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.10 seconds. MSE loss 1.10E+00. Sample per second: 467854\n",
      "FUNK_SVD: Epoch 15 of 300. Elapsed time 6.60 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.64 seconds. MSE loss 1.10E+00. Sample per second: 480636\n",
      "FUNK_SVD: Epoch 16 of 300. Elapsed time 6.87 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.34 seconds. MSE loss 1.10E+00. Sample per second: 461483\n",
      "FUNK_SVD: Epoch 17 of 300. Elapsed time 7.15 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.92 seconds. MSE loss 1.10E+00. Sample per second: 472766\n",
      "FUNK_SVD: Epoch 18 of 300. Elapsed time 7.43 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.60 seconds. MSE loss 1.09E+00. Sample per second: 454584\n",
      "FUNK_SVD: Epoch 19 of 300. Elapsed time 7.70 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.31 seconds. MSE loss 1.09E+00. Sample per second: 462235\n",
      "FUNK_SVD: Validation begins...\n",
      "EvaluatorHoldout: Processed 14001 ( 20.04% ) in 30.47 sec. Users per second: 460\n",
      "EvaluatorHoldout: Processed 29001 ( 41.50% ) in 1.03 min. Users per second: 470\n",
      "EvaluatorHoldout: Processed 44001 ( 62.97% ) in 1.54 min. Users per second: 476\n",
      "EvaluatorHoldout: Processed 59001 ( 84.43% ) in 2.05 min. Users per second: 480\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.39 min. Users per second: 488\n",
      "FUNK_SVD: CUTOFF: 5 - ROC_AUC: 0.3957206, PRECISION: 0.3257935, PRECISION_RECALL_MIN_DEN: 0.3257935, RECALL: 0.0249650, MAP: 0.2391417, MRR: 0.4898373, NDCG: 0.0708532, F1: 0.0463762, HIT_RATE: 1.6289676, ARHR: 0.7696156, RMSE: 1.0123285, NOVELTY: 0.0006415, AVERAGE_POPULARITY: 0.8144074, DIVERSITY_MEAN_INTER_LIST: 0.4346906, DIVERSITY_HERFINDAHL: 0.8869369, COVERAGE_ITEM: 0.0605367, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.0146935, SHANNON_ENTROPY: 3.7495793, \n",
      "\n",
      "FUNK_SVD: New best model found! Updating.\n",
      "FUNK_SVD: Epoch 20 of 300. Elapsed time 10.37 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.37 seconds. MSE loss 1.09E+00. Sample per second: 460648\n",
      "FUNK_SVD: Epoch 21 of 300. Elapsed time 10.65 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.06 seconds. MSE loss 1.09E+00. Sample per second: 468813\n",
      "FUNK_SVD: Epoch 22 of 300. Elapsed time 10.93 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.82 seconds. MSE loss 1.09E+00. Sample per second: 475497\n",
      "FUNK_SVD: Epoch 23 of 300. Elapsed time 11.21 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.41 seconds. MSE loss 1.08E+00. Sample per second: 459402\n",
      "FUNK_SVD: Epoch 24 of 300. Elapsed time 11.48 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.21 seconds. MSE loss 1.08E+00. Sample per second: 464767\n",
      "FUNK_SVD: Epoch 25 of 300. Elapsed time 11.76 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.94 seconds. MSE loss 1.08E+00. Sample per second: 472391\n",
      "FUNK_SVD: Epoch 26 of 300. Elapsed time 12.04 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.67 seconds. MSE loss 1.08E+00. Sample per second: 452777\n",
      "FUNK_SVD: Epoch 27 of 300. Elapsed time 12.32 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.45 seconds. MSE loss 1.08E+00. Sample per second: 458434\n",
      "FUNK_SVD: Epoch 28 of 300. Elapsed time 12.60 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.02 seconds. MSE loss 1.08E+00. Sample per second: 470042\n",
      "FUNK_SVD: Epoch 29 of 300. Elapsed time 12.88 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.85 seconds. MSE loss 1.08E+00. Sample per second: 474826\n",
      "FUNK_SVD: Validation begins...\n",
      "EvaluatorHoldout: Processed 14001 ( 20.04% ) in 30.43 sec. Users per second: 460\n",
      "EvaluatorHoldout: Processed 29001 ( 41.50% ) in 1.01 min. Users per second: 478\n",
      "EvaluatorHoldout: Processed 44001 ( 62.97% ) in 1.52 min. Users per second: 483\n",
      "EvaluatorHoldout: Processed 59001 ( 84.43% ) in 2.02 min. Users per second: 486\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.36 min. Users per second: 493\n",
      "FUNK_SVD: CUTOFF: 5 - ROC_AUC: 0.3894061, PRECISION: 0.3260998, PRECISION_RECALL_MIN_DEN: 0.3260998, RECALL: 0.0247525, MAP: 0.2385461, MRR: 0.4886082, NDCG: 0.0711125, F1: 0.0460124, HIT_RATE: 1.6304989, ARHR: 0.7672279, RMSE: 1.0048480, NOVELTY: 0.0006503, AVERAGE_POPULARITY: 0.8148935, DIVERSITY_MEAN_INTER_LIST: 0.3633112, DIVERSITY_HERFINDAHL: 0.8726612, COVERAGE_ITEM: 0.0021341, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.0605111, SHANNON_ENTROPY: 3.3103537, \n",
      "\n",
      "FUNK_SVD: Epoch 30 of 300. Elapsed time 15.52 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.39 seconds. MSE loss 1.07E+00. Sample per second: 460000\n",
      "FUNK_SVD: Epoch 31 of 300. Elapsed time 15.80 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.10 seconds. MSE loss 1.07E+00. Sample per second: 467722\n",
      "FUNK_SVD: Epoch 32 of 300. Elapsed time 16.08 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.97 seconds. MSE loss 1.07E+00. Sample per second: 471362\n",
      "FUNK_SVD: Epoch 33 of 300. Elapsed time 16.36 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.66 seconds. MSE loss 1.07E+00. Sample per second: 453081\n",
      "FUNK_SVD: Epoch 34 of 300. Elapsed time 16.64 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.39 seconds. MSE loss 1.07E+00. Sample per second: 460132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNK_SVD: Epoch 35 of 300. Elapsed time 16.92 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.18 seconds. MSE loss 1.07E+00. Sample per second: 465611\n",
      "FUNK_SVD: Epoch 36 of 300. Elapsed time 17.20 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.75 seconds. MSE loss 1.07E+00. Sample per second: 477488\n",
      "FUNK_SVD: Epoch 37 of 300. Elapsed time 17.47 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.38 seconds. MSE loss 1.07E+00. Sample per second: 460387\n",
      "FUNK_SVD: Epoch 38 of 300. Elapsed time 17.75 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.92 seconds. MSE loss 1.06E+00. Sample per second: 472691\n",
      "FUNK_SVD: Epoch 39 of 300. Elapsed time 18.03 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.60 seconds. MSE loss 1.06E+00. Sample per second: 454646\n",
      "FUNK_SVD: Validation begins...\n",
      "EvaluatorHoldout: Processed 14001 ( 20.04% ) in 30.24 sec. Users per second: 463\n",
      "EvaluatorHoldout: Processed 29001 ( 41.50% ) in 1.01 min. Users per second: 479\n",
      "EvaluatorHoldout: Processed 44001 ( 62.97% ) in 1.51 min. Users per second: 485\n",
      "EvaluatorHoldout: Processed 59001 ( 84.43% ) in 2.01 min. Users per second: 488\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.35 min. Users per second: 495\n",
      "FUNK_SVD: CUTOFF: 5 - ROC_AUC: 0.3876148, PRECISION: 0.3198460, PRECISION_RECALL_MIN_DEN: 0.3198460, RECALL: 0.0240603, MAP: 0.2332732, MRR: 0.4854420, NDCG: 0.0700835, F1: 0.0447540, HIT_RATE: 1.5992301, ARHR: 0.7558593, RMSE: 0.9992357, NOVELTY: 0.0006527, AVERAGE_POPULARITY: 0.7991084, DIVERSITY_MEAN_INTER_LIST: 0.3173072, DIVERSITY_HERFINDAHL: 0.8634605, COVERAGE_ITEM: 0.0006602, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.1783836, SHANNON_ENTROPY: 3.1760197, \n",
      "\n",
      "FUNK_SVD: Epoch 40 of 300. Elapsed time 20.66 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.39 seconds. MSE loss 1.06E+00. Sample per second: 459972\n",
      "FUNK_SVD: Epoch 41 of 300. Elapsed time 20.93 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.01 seconds. MSE loss 1.06E+00. Sample per second: 470178\n",
      "FUNK_SVD: Epoch 42 of 300. Elapsed time 21.21 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.52 seconds. MSE loss 1.06E+00. Sample per second: 456595\n",
      "FUNK_SVD: Epoch 43 of 300. Elapsed time 21.50 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.50 seconds. MSE loss 1.06E+00. Sample per second: 457092\n",
      "FUNK_SVD: Epoch 44 of 300. Elapsed time 21.79 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.14 seconds. MSE loss 1.06E+00. Sample per second: 466865\n",
      "FUNK_SVD: Epoch 45 of 300. Elapsed time 22.06 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.77 seconds. MSE loss 1.06E+00. Sample per second: 477084\n",
      "FUNK_SVD: Epoch 46 of 300. Elapsed time 22.34 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.36 seconds. MSE loss 1.06E+00. Sample per second: 460747\n",
      "FUNK_SVD: Epoch 47 of 300. Elapsed time 22.62 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.00 seconds. MSE loss 1.05E+00. Sample per second: 470462\n",
      "FUNK_SVD: Epoch 48 of 300. Elapsed time 22.89 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.71 seconds. MSE loss 1.06E+00. Sample per second: 451769\n",
      "FUNK_SVD: Epoch 49 of 300. Elapsed time 23.19 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 19.34 seconds. MSE loss 1.05E+00. Sample per second: 413601\n",
      "FUNK_SVD: Validation begins...\n",
      "EvaluatorHoldout: Processed 14001 ( 20.04% ) in 30.35 sec. Users per second: 461\n",
      "EvaluatorHoldout: Processed 29001 ( 41.50% ) in 1.01 min. Users per second: 478\n",
      "EvaluatorHoldout: Processed 44001 ( 62.97% ) in 1.52 min. Users per second: 483\n",
      "EvaluatorHoldout: Processed 59001 ( 84.43% ) in 2.03 min. Users per second: 485\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.37 min. Users per second: 492\n",
      "FUNK_SVD: CUTOFF: 5 - ROC_AUC: 0.3844128, PRECISION: 0.3143078, PRECISION_RECALL_MIN_DEN: 0.3143078, RECALL: 0.0234175, MAP: 0.2285475, MRR: 0.4824518, NDCG: 0.0690590, F1: 0.0435876, HIT_RATE: 1.5715390, ARHR: 0.7452031, RMSE: 0.9947994, NOVELTY: 0.0006549, AVERAGE_POPULARITY: 0.7844219, DIVERSITY_MEAN_INTER_LIST: 0.2783536, DIVERSITY_HERFINDAHL: 0.8556699, COVERAGE_ITEM: 0.0005681, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.1987718, SHANNON_ENTROPY: 3.0757157, \n",
      "\n",
      "FUNK_SVD: Epoch 50 of 300. Elapsed time 25.87 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.24 seconds. MSE loss 1.05E+00. Sample per second: 464098\n",
      "FUNK_SVD: Epoch 51 of 300. Elapsed time 26.15 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.96 seconds. MSE loss 1.05E+00. Sample per second: 471816\n",
      "FUNK_SVD: Epoch 52 of 300. Elapsed time 26.43 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.64 seconds. MSE loss 1.05E+00. Sample per second: 453418\n",
      "FUNK_SVD: Epoch 53 of 300. Elapsed time 26.71 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.20 seconds. MSE loss 1.05E+00. Sample per second: 465116\n",
      "FUNK_SVD: Epoch 54 of 300. Elapsed time 26.98 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.85 seconds. MSE loss 1.05E+00. Sample per second: 474841\n",
      "FUNK_SVD: Epoch 55 of 300. Elapsed time 27.26 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.41 seconds. MSE loss 1.05E+00. Sample per second: 459413\n",
      "FUNK_SVD: Epoch 56 of 300. Elapsed time 27.53 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.00 seconds. MSE loss 1.05E+00. Sample per second: 470648\n",
      "FUNK_SVD: Epoch 57 of 300. Elapsed time 27.81 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.66 seconds. MSE loss 1.05E+00. Sample per second: 452874\n",
      "FUNK_SVD: Epoch 58 of 300. Elapsed time 28.09 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.39 seconds. MSE loss 1.05E+00. Sample per second: 460080\n",
      "FUNK_SVD: Epoch 59 of 300. Elapsed time 28.37 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.04 seconds. MSE loss 1.05E+00. Sample per second: 469432\n",
      "FUNK_SVD: Validation begins...\n",
      "EvaluatorHoldout: Processed 14001 ( 20.04% ) in 30.17 sec. Users per second: 464\n",
      "EvaluatorHoldout: Processed 29001 ( 41.50% ) in 1.01 min. Users per second: 480\n",
      "EvaluatorHoldout: Processed 44001 ( 62.97% ) in 1.51 min. Users per second: 485\n",
      "EvaluatorHoldout: Processed 59001 ( 84.43% ) in 2.02 min. Users per second: 488\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.35 min. Users per second: 495\n",
      "FUNK_SVD: CUTOFF: 5 - ROC_AUC: 0.3809890, PRECISION: 0.3095051, PRECISION_RECALL_MIN_DEN: 0.3095051, RECALL: 0.0228744, MAP: 0.2243289, MRR: 0.4794020, NDCG: 0.0680785, F1: 0.0426004, HIT_RATE: 1.5475257, ARHR: 0.7355243, RMSE: 0.9911864, NOVELTY: 0.0006566, AVERAGE_POPULARITY: 0.7727042, DIVERSITY_MEAN_INTER_LIST: 0.2487447, DIVERSITY_HERFINDAHL: 0.8497482, COVERAGE_ITEM: 0.0005066, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.2156798, SHANNON_ENTROPY: 3.0087312, \n",
      "\n",
      "FUNK_SVD: Epoch 60 of 300. Elapsed time 31.00 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.14 seconds. MSE loss 1.04E+00. Sample per second: 466654\n",
      "FUNK_SVD: Epoch 61 of 300. Elapsed time 31.28 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.69 seconds. MSE loss 1.05E+00. Sample per second: 479413\n",
      "FUNK_SVD: Epoch 62 of 300. Elapsed time 31.56 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.40 seconds. MSE loss 1.04E+00. Sample per second: 459849\n",
      "FUNK_SVD: Epoch 63 of 300. Elapsed time 31.83 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.09 seconds. MSE loss 1.04E+00. Sample per second: 468228\n",
      "FUNK_SVD: Epoch 64 of 300. Elapsed time 32.11 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.80 seconds. MSE loss 1.04E+00. Sample per second: 476094\n",
      "FUNK_SVD: Epoch 65 of 300. Elapsed time 32.39 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.42 seconds. MSE loss 1.04E+00. Sample per second: 459255\n",
      "FUNK_SVD: Epoch 66 of 300. Elapsed time 32.67 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.03 seconds. MSE loss 1.04E+00. Sample per second: 469826\n",
      "FUNK_SVD: Epoch 67 of 300. Elapsed time 32.94 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.77 seconds. MSE loss 1.04E+00. Sample per second: 476953\n",
      "FUNK_SVD: Epoch 68 of 300. Elapsed time 33.22 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 17.30 seconds. MSE loss 1.04E+00. Sample per second: 462480\n",
      "FUNK_SVD: Epoch 69 of 300. Elapsed time 33.50 min\n",
      "FUNK_SVD: Processed 8000000 ( 99.99% ) in 16.86 seconds. MSE loss 1.04E+00. Sample per second: 474601\n",
      "FUNK_SVD: Validation begins...\n",
      "EvaluatorHoldout: Processed 14001 ( 20.04% ) in 30.01 sec. Users per second: 467\n",
      "EvaluatorHoldout: Processed 29001 ( 41.50% ) in 1.00 min. Users per second: 482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 44001 ( 62.97% ) in 1.51 min. Users per second: 486\n",
      "EvaluatorHoldout: Processed 59001 ( 84.43% ) in 2.01 min. Users per second: 488\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.35 min. Users per second: 495\n",
      "FUNK_SVD: CUTOFF: 5 - ROC_AUC: 0.3765849, PRECISION: 0.3058101, PRECISION_RECALL_MIN_DEN: 0.3058101, RECALL: 0.0224756, MAP: 0.2209573, MRR: 0.4764926, NDCG: 0.0672830, F1: 0.0418737, HIT_RATE: 1.5290506, ARHR: 0.7273047, RMSE: 0.9880807, NOVELTY: 0.0006580, AVERAGE_POPULARITY: 0.7635722, DIVERSITY_MEAN_INTER_LIST: 0.2304001, DIVERSITY_HERFINDAHL: 0.8460794, COVERAGE_ITEM: 0.0005374, COVERAGE_USER: 0.9763861, DIVERSITY_GINI: 0.1995526, SHANNON_ENTROPY: 2.9767800, \n",
      "\n",
      "FUNK_SVD: Convergence reached! Terminating at epoch 70. Best value for 'MAP' at epoch 20 is 0.2391. Elapsed time 36.13 min\n",
      "FUNK_SVD: Epoch 70 of 300. Elapsed time 36.13 min\n",
      "EvaluatorHoldout: Processed 14929 ( 21.39% ) in 30.00 sec. Users per second: 498\n",
      "EvaluatorHoldout: Processed 30001 ( 42.98% ) in 1.03 min. Users per second: 486\n",
      "EvaluatorHoldout: Processed 45282 ( 64.87% ) in 1.53 min. Users per second: 494\n",
      "EvaluatorHoldout: Processed 60303 ( 86.39% ) in 2.03 min. Users per second: 495\n",
      "EvaluatorHoldout: Processed 69805 ( 100.00% ) in 2.33 min. Users per second: 500\n"
     ]
    }
   ],
   "source": [
    "recommender = MatrixFactorization_FunkSVD_Cython(URM_train)\n",
    "recommender.fit(num_factors = 50, \n",
    "                validation_every_n = 10, \n",
    "                stop_on_validation = True, \n",
    "                evaluator_object = evaluator_validation_early_stopping,\n",
    "                lower_validations_allowed = 5, \n",
    "                validation_metric = \"MAP\")\n",
    "\n",
    "result_dict, _ = evaluator_test.evaluateRecommender(recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDRecommender: URM Detected 1690 (2.36 %) cold users.\n",
      "PureSVDRecommender: URM Detected 54481 (83.64 %) cold items.\n",
      "PureSVDRecommender: Computing SVD decomposition...\n",
      "PureSVDRecommender: Computing SVD decomposition... Done!\n",
      "EvaluatorHoldout: Processed 23001 ( 32.95% ) in 30.32 sec. Users per second: 759\n",
      "EvaluatorHoldout: Processed 48406 ( 69.34% ) in 1.01 min. Users per second: 802\n",
      "EvaluatorHoldout: Processed 69805 ( 100.00% ) in 1.43 min. Users per second: 815\n"
     ]
    }
   ],
   "source": [
    "recommender = PureSVDRecommender(URM_train)\n",
    "recommender.fit()\n",
    "\n",
    "result_dict, _ = evaluator_test.evaluateRecommender(recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
