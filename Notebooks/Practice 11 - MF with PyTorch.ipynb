{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems 2018/19\n",
    "\n",
    "### Practice session on MF PyTorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataReader: Verifying data consistency...\n",
      "DataReader: Verifying data consistency... Passed!\n",
      "DataReader: current dataset is: <class 'Data_manager.Movielens10M.Movielens10MReader.Movielens10MReader'>\n",
      "\tNumber of items: 10680\n",
      "\tNumber of users: 69878\n",
      "\tNumber of interactions in URM_all: 9973605\n",
      "\tInteraction density: 1.34E-02\n",
      "\tInteractions per user:\n",
      "\t\t Min: 1.90E+01\n",
      "\t\t Avg: 1.43E+02\n",
      "\t\t Max: 7.36E+03\n",
      "\tInteractions per item:\n",
      "\t\t Min: 0.00E+00\n",
      "\t\t Avg: 9.34E+02\n",
      "\t\t Max: 3.49E+04\n",
      "\tGini Index: 0.57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Notebooks_utils.data_splitter import train_test_holdout\n",
    "from Data_manager.Movielens10M.Movielens10MReader import Movielens10MReader\n",
    "\n",
    "data_reader = Movielens10MReader()\n",
    "data_reader.load_data()\n",
    "\n",
    "URM_all = data_reader.get_URM_all()\n",
    "\n",
    "URM_train, URM_test = train_test_holdout(URM_all, train_perc = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MF models rely upon latent factors for users and items which are called 'embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factors = 10\n",
    "\n",
    "n_users, n_items = URM_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "user_factors = torch.nn.Embedding(num_embeddings = n_users, embedding_dim = num_factors)\n",
    "item_factors = torch.nn.Embedding(num_embeddings = n_items, embedding_dim = num_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(69878, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(10680, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To compute the prediction we have to multiply the user factors to the item factors, which is a linear operation.\n",
    "\n",
    "### We define a single layer and an activation function, which takes the result and transforms it in the final prediction. The activation function can be used to restrict the predicted values (e.g., sigmoid is between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=1, bias=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1 = torch.nn.Linear(in_features = num_factors, out_features = 1)\n",
    "\n",
    "layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_function = torch.nn.ReLU()\n",
    "\n",
    "activation_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to compute the prediction you have to:\n",
    "* Define a list of user and item indices\n",
    "* Create a tensor from it\n",
    "* Create a variable from the tensor\n",
    "* Get the user and item embedding\n",
    "* Compute the element-wise product of the embeddings\n",
    "* Pass the element-wise product to the single layer network\n",
    "* Pass the output of the single layer network to the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1633,  0.7963,  1.9864, -0.8203,  0.1206, -1.0947,  0.4731, -0.3108,\n",
       "          0.5729, -6.5700]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "item_index = [15]\n",
    "user_index = [42]\n",
    "\n",
    "user_index = torch.Tensor(user_index).type(torch.LongTensor)\n",
    "item_index = torch.Tensor(item_index).type(torch.LongTensor)\n",
    "\n",
    "user_index = Variable(user_index)\n",
    "item_index = Variable(item_index)\n",
    "\n",
    "current_user_factors = user_factors(user_index)\n",
    "current_item_factors = item_factors(item_index)\n",
    "\n",
    "element_wise_product = torch.mul(current_user_factors, current_item_factors)\n",
    "element_wise_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To take the result of the prediction and transform it into a traditional numpy array you have to first call .detach() and then .numpy()\n",
    "### The result is an array of 1 cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is [[0.08442144]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction = layer_1(element_wise_product)\n",
    "prediction = activation_function(prediction)\n",
    "\n",
    "prediction_numpy = prediction.detach().numpy()\n",
    "\n",
    "print(\"Prediction is {}\".format(prediction_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a MF MSE model with PyTorch\n",
    "\n",
    "# Step 1 Create a Model python object\n",
    "\n",
    "### The model should implement the forward function which computes the prediction as we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MF_MSE_PyTorch_model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "\n",
    "        super(MF_MSE_PyTorch_model, self).__init__()\n",
    "\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.n_factors = n_factors\n",
    "\n",
    "        self.user_factors = torch.nn.Embedding(num_embeddings = self.n_users, embedding_dim = self.n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(num_embeddings = self.n_items, embedding_dim = self.n_factors)\n",
    "\n",
    "        self.layer_1 = torch.nn.Linear(in_features = self.n_factors, out_features = 1)\n",
    "\n",
    "        self.activation_function = torch.nn.ReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, user_coordinates, item_coordinates):\n",
    "\n",
    "        current_user_factors = self.user_factors(user_coordinates)\n",
    "        current_item_factors = self.item_factors(item_coordinates)\n",
    "\n",
    "        prediction = torch.mul(current_user_factors, current_item_factors)\n",
    "\n",
    "        prediction = self.layer_1(prediction)\n",
    "        prediction = self.activation_function(prediction)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "\n",
    "\n",
    "    def get_W(self):\n",
    "\n",
    "        return self.user_factors.weight.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    def get_H(self):\n",
    "\n",
    "        return self.item_factors.weight.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Setup PyTorch devices and Data Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF_MSE_PyTorch: Using CPU\n"
     ]
    }
   ],
   "source": [
    "use_cuda = False\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"MF_MSE_PyTorch: Using CUDA\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"MF_MSE_PyTorch: Using CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of the model and specify the device it should run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyTorchModel = MF_MSE_PyTorch_model(n_users, n_items, num_factors).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose loss functions, there are quite a few to choose from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferra\\Anaconda3\\envs\\RecSysFramework\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "lossFunction = torch.nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the optimizer to be used for the model parameters: Adam, AdaGrad, RMSProp etc... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adagrad(pyTorchModel.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the DatasetIterator, which will be used to iterate over the data\n",
    "\n",
    "### A DatasetIterator will implement the Dataset class and provide the __getitem__(self, index) method, which allows to get the data points indexed by that index.\n",
    "\n",
    "### Since we need the data to be a tensor, we pre inizialize everything as a tensor. In practice we save the URM in coordinate format (user, item, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class DatasetIterator_URM(Dataset):\n",
    "\n",
    "    def __init__(self, URM):\n",
    "\n",
    "        URM = URM.tocoo()\n",
    "\n",
    "        self.n_data_points = URM.nnz\n",
    "\n",
    "        self.user_item_coordinates = np.empty((self.n_data_points, 2))\n",
    "\n",
    "        self.user_item_coordinates[:,0] = URM.row.copy()\n",
    "        self.user_item_coordinates[:,1] = URM.col.copy()\n",
    "        self.rating = URM.data.copy().astype(np.float)\n",
    "\n",
    "        self.user_item_coordinates = torch.Tensor(self.user_item_coordinates).type(torch.LongTensor)\n",
    "        self.rating = torch.Tensor(self.rating)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Format is (row, col, data)\n",
    "        :param index:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        return self.user_item_coordinates[index, :], self.rating[index]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.n_data_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We pass the DatasetIterator to a DataLoader object which manages the use of batches and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "dataset_iterator = DatasetIterator_URM(URM_train)\n",
    "\n",
    "train_data_loader = DataLoader(dataset = dataset_iterator,\n",
    "                   batch_size = batch_size,\n",
    "                   shuffle = True,\n",
    "                   #num_workers = 2,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now we ran the usual epoch steps\n",
    "* Data point sampling\n",
    "* Prediction computation\n",
    "* Loss function computation\n",
    "* Gradient computation\n",
    "* Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 of 39902, loss 2693.2285\n",
      "Batch 100 of 39902, loss 2569.2058\n",
      "Batch 200 of 39902, loss 2712.8464\n",
      "Batch 300 of 39902, loss 2510.9595\n",
      "Batch 400 of 39902, loss 2756.1619\n",
      "Batch 500 of 39902, loss 2772.4038\n",
      "Batch 600 of 39902, loss 2699.5073\n",
      "Batch 700 of 39902, loss 2679.5432\n",
      "Batch 800 of 39902, loss 2543.4636\n",
      "Batch 900 of 39902, loss 2559.9866\n",
      "Batch 1000 of 39902, loss 2758.6155\n",
      "Batch 1100 of 39902, loss 2591.0347\n",
      "Batch 1200 of 39902, loss 2512.6665\n",
      "Batch 1300 of 39902, loss 2594.8857\n",
      "Batch 1400 of 39902, loss 2634.5295\n",
      "Batch 1500 of 39902, loss 2652.8567\n",
      "Batch 1600 of 39902, loss 2650.3032\n",
      "Batch 1700 of 39902, loss 2702.7373\n",
      "Batch 1800 of 39902, loss 2487.4812\n",
      "Batch 1900 of 39902, loss 2503.0127\n",
      "Batch 2000 of 39902, loss 2438.5083\n",
      "Interrupting train\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for num_batch, (input_data, label) in enumerate(train_data_loader, 0):\n",
    "    \n",
    "    cumulative_loss = 0\n",
    "\n",
    "    # On windows requires int64, on ubuntu int32\n",
    "    #input_data_tensor = Variable(torch.from_numpy(np.asarray(input_data, dtype=np.int64))).to(self.device)\n",
    "    input_data_tensor = Variable(input_data).to(device)\n",
    "\n",
    "    label_tensor = Variable(label).to(device)\n",
    "\n",
    "\n",
    "    user_coordinates = input_data_tensor[:,0]\n",
    "    item_coordinates = input_data_tensor[:,1]\n",
    "\n",
    "    # FORWARD pass\n",
    "    prediction = pyTorchModel(user_coordinates, item_coordinates)\n",
    "\n",
    "    # Pass prediction and label removing last empty dimension of prediction\n",
    "    loss = lossFunction(prediction.view(-1), label_tensor)\n",
    "    \n",
    "\n",
    "    if num_batch % 100 == 0:\n",
    "        \n",
    "        print(\"Batch {} of {}, loss {:.4f}\".format(num_batch, len(train_data_loader), loss.data.item()))\n",
    "        \n",
    "        if num_batch == 2000:\n",
    "            print(\"Interrupting train\")\n",
    "            break\n",
    "    \n",
    "\n",
    "    # BACKWARD pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After the train is complete (it may take a while and many epochs), we can get the matrices in the usual numpy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = pyTorchModel.get_W()\n",
    "H = pyTorchModel.get_H()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3723019 ,  1.2319666 ,  0.01198455, ..., -0.65794045,\n",
       "        -0.7925086 ,  0.5564781 ],\n",
       "       [ 0.8585925 ,  0.16828233,  0.72623336, ...,  0.16024801,\n",
       "        -0.56704813,  2.2603905 ],\n",
       "       [ 0.26224038, -0.7109332 ,  0.0401555 , ...,  0.2451228 ,\n",
       "         0.05146181,  0.5744626 ],\n",
       "       ...,\n",
       "       [-1.1616576 , -0.06856933, -1.2849674 , ..., -1.6088682 ,\n",
       "         0.61678284,  0.8829945 ],\n",
       "       [ 0.39393863,  0.9772253 ,  0.8669473 , ..., -1.1229942 ,\n",
       "         1.3125156 , -0.3003385 ],\n",
       "       [ 1.8895546 ,  0.20086485, -0.8687518 , ..., -1.1064979 ,\n",
       "        -1.2153162 ,  0.52877593]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2143894 , -0.58902395,  0.29043895, ...,  0.64703804,\n",
       "         0.43375066,  0.07141441],\n",
       "       [-0.22804576,  0.6213643 ,  3.2913234 , ..., -1.7908198 ,\n",
       "         0.9197715 , -0.89540195],\n",
       "       [-0.5257621 , -0.14976846, -0.17263614, ..., -0.46387058,\n",
       "        -0.10895726, -0.780038  ],\n",
       "       ...,\n",
       "       [-0.21858367,  0.19782965,  0.29153433, ..., -0.02902405,\n",
       "         1.1861417 ,  0.3214013 ],\n",
       "       [-0.7174214 , -0.8532166 , -1.2287543 , ...,  0.17205659,\n",
       "         0.9493459 ,  0.13268645],\n",
       "       [-1.4975051 ,  2.3539457 , -0.12908785, ...,  0.17214388,\n",
       "        -0.1299802 , -0.576439  ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
